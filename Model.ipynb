{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "TZ9rtHh5R0jb"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dCvurSR0iMAu",
    "outputId": "09ad70d1-6a8c-49c1-f1e9-b974b758e715"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(93239, 2)"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('news.csv', sep=',') # or sampled_news_final.csv\n",
    "dataset = dataset.drop(['Unnamed: 0', 'Title', 'SentimentTitle'], axis=1)\n",
    "dataset.columns = ['text', 'sentiment']\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "7U1L1a2AQnxu",
    "outputId": "1e94e12b-9cba-4d40-e32a-d896309c5ba2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Obama Lays Wreath at Arlington National Cemete...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tim Haywood, investment director business-unit...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nouriel Roubini, NYU professor and chairman at...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Finland's economy expanded marginally in the t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tourism and public spending continued to boost...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  sentiment\n",
       "0  Obama Lays Wreath at Arlington National Cemete...          1\n",
       "1  Tim Haywood, investment director business-unit...          1\n",
       "2  Nouriel Roubini, NYU professor and chairman at...          1\n",
       "3  Finland's economy expanded marginally in the t...          1\n",
       "4  Tourism and public spending continued to boost...          1"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EwP4BVnYE6f3",
    "outputId": "9ebb76fe-a6df-424e-a625-1d7f59234eb4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    92990\n",
       "0      158\n",
       "2       91\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "HE7kD-nXR0lC"
   },
   "outputs": [],
   "source": [
    "X, y = dataset['text'].astype(str).tolist(), dataset['sentiment'].tolist()\n",
    "NUM_CLASSES = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DgF9Mt_FR0lM",
    "outputId": "2b560938-d524-4599-a911-2da1a6dcee4b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61\n"
     ]
    }
   ],
   "source": [
    "tokenizer = tf.keras.preprocessing.text.Tokenizer()\n",
    "\n",
    "tokenizer.fit_on_texts(X)\n",
    "X_encoded = tokenizer.texts_to_sequences(X)\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "MAX_LEN = max([len(n) for n in X_encoded])\n",
    "print(MAX_LEN)\n",
    "X_encoded = tf.keras.preprocessing.sequence.pad_sequences(X_encoded, maxlen=MAX_LEN)\n",
    "\n",
    "# One Hot Encoding Target\n",
    "y_encoded = np.eye(NUM_CLASSES, dtype='int')[y].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3O99E3oznKrL",
    "outputId": "193d03bb-5430-4214-cc64-76d35a47f7fb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((250921, 61), (27881, 61), (250921, 3), (27881, 3))"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X_encoded, y_encoded, test_size=0.1)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LWcf0w44R0lo"
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "z38d6f21se_k"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Embeddings():\n",
    "    def __init__(self, path, vector_dimension):\n",
    "        self.path = path \n",
    "        self.vector_dimension = vector_dimension\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_coefs(word, *arr): \n",
    "        return word, np.asarray(arr)\n",
    "\n",
    "    def get_embedding_index(self):\n",
    "        embeddings_index = dict(self.get_coefs(*o.split(\" \")) for o in open(self.path, 'r', errors='ignore', encoding='utf-8'))\n",
    "        return embeddings_index\n",
    "\n",
    "    def create_embedding_matrix(self, tokenizer, max_features):\n",
    "        model_embed = self.get_embedding_index()\n",
    "        embedding_matrix = np.zeros((max_features + 1, self.vector_dimension))\n",
    "        for word, index in tokenizer.word_index.items():\n",
    "            if index > max_features:\n",
    "                break\n",
    "            else:\n",
    "                try:\n",
    "                    embedding_matrix[index] = model_embed[word]\n",
    "                except:\n",
    "                    continue\n",
    "        return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "4H1aFGfotg8c"
   },
   "outputs": [],
   "source": [
    "#Word embedding\n",
    "\n",
    "#Import GloVe embeddings or other pretrained embeddings\n",
    "embedding = Embeddings(\n",
    "    path = 'glove.6B.200d.txt',\n",
    "    vector_dimension = 200,\n",
    ")\n",
    "\n",
    "embedding_matrix = embedding.create_embedding_matrix(tokenizer, vocab_size)\n",
    "embedding_dim = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "jJh8aBkTqiql"
   },
   "outputs": [],
   "source": [
    "class MultiHeadSelfAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads=8):\n",
    "        super(MultiHeadSelfAttention, self).__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        if embed_dim % num_heads != 0:\n",
    "            raise ValueError(\n",
    "                f\"embedding dimension = {embed_dim} should be divisible by number of heads = {num_heads}\"\n",
    "            )\n",
    "        self.projection_dim = embed_dim // num_heads\n",
    "        self.query_dense = tf.keras.layers.Dense(embed_dim)\n",
    "        self.key_dense = tf.keras.layers.Dense(embed_dim)\n",
    "        self.value_dense = tf.keras.layers.Dense(embed_dim)\n",
    "        self.combine_heads = tf.keras.layers.Dense(embed_dim)\n",
    "\n",
    "    def attention(self, query, key, value):\n",
    "        score = tf.matmul(query, key, transpose_b=True)\n",
    "        dim_key = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "        scaled_score = score / tf.math.sqrt(dim_key)\n",
    "        weights = tf.nn.softmax(scaled_score, axis=-1)\n",
    "        output = tf.matmul(weights, value)\n",
    "        return output, weights\n",
    "\n",
    "    def separate_heads(self, x, batch_size):\n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.projection_dim))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # x.shape = [batch_size, seq_len, embedding_dim]\n",
    "        batch_size = tf.shape(inputs)[0]\n",
    "        query = self.query_dense(inputs)  # (batch_size, seq_len, embed_dim)\n",
    "        key = self.key_dense(inputs)  # (batch_size, seq_len, embed_dim)\n",
    "        value = self.value_dense(inputs)  # (batch_size, seq_len, embed_dim)\n",
    "        query = self.separate_heads(\n",
    "            query, batch_size\n",
    "        )  # (batch_size, num_heads, seq_len, projection_dim)\n",
    "        key = self.separate_heads(\n",
    "            key, batch_size\n",
    "        )  # (batch_size, num_heads, seq_len, projection_dim)\n",
    "        value = self.separate_heads(\n",
    "            value, batch_size\n",
    "        )  # (batch_size, num_heads, seq_len, projection_dim)\n",
    "        attention, weights = self.attention(query, key, value)\n",
    "        attention = tf.transpose(\n",
    "            attention, perm=[0, 2, 1, 3]\n",
    "        )  # (batch_size, seq_len, num_heads, projection_dim)\n",
    "        concat_attention = tf.reshape(\n",
    "            attention, (batch_size, -1, self.embed_dim)\n",
    "        )  # (batch_size, seq_len, embed_dim)\n",
    "        output = self.combine_heads(\n",
    "            concat_attention\n",
    "        )  # (batch_size, seq_len, embed_dim)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "jRdKNIoRTyvh"
   },
   "outputs": [],
   "source": [
    "def categorical_focal_loss(classes_num, gamma=4., alpha=.25, e=0.1):\n",
    "    def focal_loss_fixed(target_tensor, prediction_tensor):\n",
    "        import tensorflow as tf\n",
    "        from tensorflow.python.ops import array_ops\n",
    "        from keras import backend as K\n",
    "        \n",
    "        #1# get focal loss with no balanced weight which presented in paper function (4)\n",
    "        zeros = array_ops.zeros_like(prediction_tensor, dtype=prediction_tensor.dtype)\n",
    "        one_minus_p = array_ops.where(tf.greater(target_tensor,zeros), target_tensor - prediction_tensor, zeros)\n",
    "        FT = -1 * (one_minus_p ** gamma) * tf.math.log(tf.clip_by_value(prediction_tensor, 1e-8, 1.0))\n",
    "\n",
    "        #2# get balanced weight alpha\n",
    "        classes_weight = array_ops.zeros_like(prediction_tensor, dtype=prediction_tensor.dtype)\n",
    "\n",
    "        total_num = float(sum(classes_num))\n",
    "        classes_w_t1 = [ total_num / ff for ff in classes_num ]\n",
    "        sum_ = sum(classes_w_t1)\n",
    "        classes_w_t2 = [ ff/sum_ for ff in classes_w_t1 ]   #scale\n",
    "        classes_w_tensor = tf.convert_to_tensor(classes_w_t2, dtype=prediction_tensor.dtype)\n",
    "        classes_weight += classes_w_tensor\n",
    "\n",
    "        alpha = array_ops.where(tf.greater(target_tensor, zeros), classes_weight, zeros)\n",
    "\n",
    "        #3# get balanced focal loss\n",
    "        balanced_fl = alpha * FT\n",
    "        balanced_fl = tf.reduce_mean(balanced_fl)\n",
    "\n",
    "        #4# add other op to prevent overfit\n",
    "        # reference : https://spaces.ac.cn/archives/4493\n",
    "        nb_classes = len(classes_num)\n",
    "        fianal_loss = (1-e) * balanced_fl + e * K.categorical_crossentropy(K.ones_like(prediction_tensor)/nb_classes, prediction_tensor)\n",
    "\n",
    "        return fianal_loss\n",
    "    return focal_loss_fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "g_F8WxcNYLAH"
   },
   "outputs": [],
   "source": [
    "class TransformerBlock(tf.keras.Model):\n",
    "    def __init__(self, embed_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Check embeddings and attention dimensions\n",
    "        self.attn = MultiHeadSelfAttention(embed_dim, 4)\n",
    "\n",
    "        self.leakyrelu = tf.keras.layers.LeakyReLU()\n",
    "\n",
    "        self.ffn = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(128, activation=self.leakyrelu),\n",
    "            tf.keras.layers.Dropout(0.5),\n",
    "            tf.keras.layers.Dense(64, activation=self.leakyrelu),\n",
    "            tf.keras.layers.Dense(embed_dim, activation=self.leakyrelu),\n",
    "            ])\n",
    "        \n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.dropout1 = tf.keras.layers.Dropout(0.5)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(0.5)\n",
    "\n",
    "    def call(self, inp, training=False):\n",
    "        x = self.attn(inp)\n",
    "        x = self.dropout1(x)\n",
    "        out_norm1 = self.layernorm1(tf.cast(inp, x.dtype) + x) \n",
    "        x = self.ffn(out_norm1)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.layernorm2(x + out_norm1)\n",
    "\n",
    "        return x\n",
    "\n",
    "class Model(tf.keras.Model):\n",
    "    def __init__(self, embed_dim):\n",
    "        super().__init__(self)\n",
    "        self.embedding_layer = tf.keras.layers.Embedding(vocab_size+1, \n",
    "                                    embedding_dim, \n",
    "                                    weights=[embedding_matrix])\n",
    "        self.transformer_block = TransformerBlock(embed_dim)\n",
    "        self.average_pooling = tf.keras.layers.GlobalAveragePooling1D()\n",
    "        self.dropout1 = tf.keras.layers.Dropout(0.5)\n",
    "        self.ffn = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(128, activation='softmax'),\n",
    "            tf.keras.layers.Dropout(0.5),\n",
    "            tf.keras.layers.Dense(128, activation='softmax'),\n",
    "            tf.keras.layers.Dropout(0.5),\n",
    "            tf.keras.layers.Dense(64, activation='softmax'),\n",
    "            tf.keras.layers.Dropout(0.5)\n",
    "            ])\n",
    "        self.dense2 = tf.keras.layers.Dense(NUM_CLASSES, activation=\"softmax\")\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.embedding_layer(inputs)\n",
    "        x = self.transformer_block(x)\n",
    "        x = self.average_pooling(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.ffn(x) \n",
    "        x = self.dense2(x) \n",
    "        return x\n",
    "        \n",
    "def optimizer():\n",
    "    return tf.keras.optimizers.Adam()\n",
    "\n",
    "def create_model(classes):\n",
    "    model = Model(embed_dim=embedding_dim)\n",
    "    opt = optimizer()\n",
    "    model.compile(loss=[categorical_focal_loss(classes)], optimizer=opt, metrics=[\"acc\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "1WmN_ceJHlLs"
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight\n",
    "\n",
    "class_weights = class_weight.compute_class_weight('balanced',np.unique(y),y)\n",
    "dict_class_weights = dict(enumerate(class_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PaRlxdrTR0l-",
    "outputId": "21137b7b-3435-43aa-922f-38ee315b3697"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "7842/7842 [==============================] - 606s 77ms/step - loss: 0.1297 - acc: 0.4421 - val_loss: 0.1245 - val_acc: 0.6647\n",
      "Epoch 2/2\n",
      "7842/7842 [==============================] - 597s 76ms/step - loss: 0.1257 - acc: 0.6289 - val_loss: 0.1242 - val_acc: 0.6691\n"
     ]
    }
   ],
   "source": [
    "model = create_model(class_weights)\n",
    "history = model.fit(X_train, y_train, epochs=2, validation_data=(X_test, y_test), class_weight=dict_class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yyz1QXC_hi-h",
    "outputId": "d74842cd-a3f2-4854-ebe7-10989186dbbd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      multiple                  7600200   \n",
      "_________________________________________________________________\n",
      "transformer_block_1 (Transfo multiple                  208584    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_1 ( multiple                  0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         multiple                  0         \n",
      "_________________________________________________________________\n",
      "sequential_3 (Sequential)    (None, 64)                50496     \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             multiple                  195       \n",
      "=================================================================\n",
      "Total params: 7,859,475\n",
      "Trainable params: 7,859,475\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bZgZ5ye3OfyI"
   },
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 333
    },
    "id": "g6MjAWLyR4hG",
    "outputId": "7dd65596-35bc-4bcb-95af-c3b090ea6f3b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    0 92990     0]\n",
      " [    0 92990     0]\n",
      " [    0 92822     0]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
    "\n",
    "y_pred = [np.argmax(p) for p in model.predict(y_encoded)]\n",
    "cm = confusion_matrix(y_true=[np.argmax(i) for i in y_encoded], y_pred=y_pred, labels=[0,1,2])\n",
    "print(cm)\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[0,1,2]).plot(include_values=True)\n",
    "plt.savefig('bar.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F74jxUe6R_ds"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "y_pred = [np.argmax(p) for p in model.predict(y_encoded)]\n",
    "y_pred = np.eye(NUM_CLASSES)[y_pred]\n",
    "\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(NUM_CLASSES):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_encoded[:, i], y_pred[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Plot of a ROC curve for a specific class\n",
    "for i in range(NUM_CLASSES):\n",
    "    plt.figure()\n",
    "    plt.plot(fpr[i], tpr[i], label='ROC curve (area = %0.2f)' % roc_auc[i], color='orange')\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic class %s' % i)\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Model.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
